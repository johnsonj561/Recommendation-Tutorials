{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Personal Recommendation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We don't always know our user's preferences, e.g. new users\n",
    "- We can user patterns from the populations behavior to make suggestions\n",
    "- In many examples, no machine learning is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity Ranking\n",
    "\n",
    "- other people really liked it, so you probably will too\n",
    "\n",
    "### Challenges\n",
    "\n",
    "- McDonald's is popular, should we recommend that? Probably not\n",
    "- top 40 music is popular, but many people won't like it\n",
    "- age can be an important factor to consider, we should usually consider this\n",
    "- news from last week is popular, but we don't want to see old news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity Analysis\n",
    "\n",
    "- also known as Association Rule mining, identifying Frequent Item Sets, or Market Basket analysis\n",
    "- technique is used for making \"context-based\" recommendations\n",
    "- if you're buying an iPhone, you might also want an iPhone case\n",
    "\n",
    "### Conditional Probability\n",
    "\n",
    "- compute the probability of purchasing item A given context of item B\n",
    "- this will lead to many false positives, we need to be smarter\n",
    "\n",
    "$$P(A \\mid B) = \\frac{count(A,B)}{count(B)}$$\n",
    "\n",
    "### Lift\n",
    "\n",
    "- in association rule mining, a Lift score is the performance ratio of a target model divided by a random choice or default model\n",
    "- Lift can also be used for context-based recommendations\n",
    "- the Lift score increases (> 1) when buying one item (B) makes buying another item (A) more likely\n",
    "\n",
    "$$Lift = \\frac{p(A,B)}{p(A)p(B)} = \\frac{p(A \\mid B)}{p(A)} = \\frac{p(B \\mid A)}{p(B)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacker News - Popularity Over Time\n",
    "\n",
    "$$score = \\frac{(upvotes - downvotes - 1)^{0.8}}{(age + 2)^{gravity}} \\times penalty$$\n",
    "\n",
    "- Hacker News ranking considers up votes, down votes, age, and penalties\n",
    "- numerator is a measure of article popularity\n",
    "- sublinear numerator (exponent < 1) because\n",
    "    - age must overpower popularity over time\n",
    "    - first 100 votes should carry more meaning than 1000-1100 votes\n",
    "    - very few articles make up most of the votes, and many articles have just a few votes\n",
    "- penalty terms include self-posts, controversial posts, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0, 100, 1)\n",
    "y = x ** 0.8\n",
    "plt.plot(x, y)\n",
    "plt.ylim(0, 100)\n",
    "plt.title('Sublinear Popularity Score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Rating Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- average item ratings is the easiest way to score items\n",
    "\n",
    "### Challenges\n",
    "\n",
    "- not always as simple as upvotes and downvotes, e.g. 5 star systems\n",
    "- some items have very few ratings, i.e. confidence of average is low\n",
    "\n",
    "### Using Confidence Intervals\n",
    "\n",
    "$$95\\% CI = (\\bar{X} +- z_{score}\\frac{s}{\\sqrt{N}})$$\n",
    "\n",
    "- as total number of ratings increases, estimated averaged approaches the expected rating\n",
    "- compute the confidence interval for an item's rating and use the lower bound\n",
    "- popularity will increase score by creating tighter confidence intervals, i.e. higher lower bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with Average Ratings\n",
    "\n",
    "- 5 star ratings can leverage Wilson's interval\n",
    "- we can convert each possible rating to a upvote and downvote percentage, e.g. 0 star is 1 downvote 0 upvote, 3 star is 0.5 downvote and 0.5 upvote, and 5 star is 0 downvotes and 1 upvote\n",
    "- what if there are 0 ratings? We need to use smoothing to prevent divide by 0\n",
    "- Laplace smoothing is common solution, also used in NLP\n",
    "- this allows us to obtain smooth transition as number of voters increases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore-Exploit Dilemma\n",
    "\n",
    "- if you're at casino and there is row of slot machines, you can't tell which one is the best, you must play them to see which one has best rewards\n",
    "- you need to calculate the win rate for each slot machine to determine which one to play (exploit)\n",
    "- how many times should you play each slot machine (explore)?\n",
    "  - if you play too few, your estimate will have large confidence interval\n",
    "  - if you play too many, you are missing opportunity to explore other machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- explore-exploit is faced when recommending items to users, and exploration is needed to encourage new, novel items\n",
    "- exploring too much runs the risk of bad recommendations, but not exploring can be a bad user experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Methods for the Explore-Exploit Challenge\n",
    "\n",
    "AKA Bayesian Bandits\n",
    "\n",
    "- we want to know the probability that a user will click on a recommendation\n",
    "- can be applied to AB testing, Ad clicks, selecting stocks, etc\n",
    "- we can draw recommendations from beta distributions and update these distributions with the customer feedback\n",
    "- this allows for easy online learning\n",
    "\n",
    "### Beta Distribution\n",
    "\n",
    "A continuous probability distribution defined on [0,1] with 2 parameters, $\\alpha$ and $\\beta$.\n",
    "\n",
    "$$\\text{Beta PDF} = f(x;\\alpha,\\beta) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha, \\beta)}$$\n",
    "\n",
    "When $\\alpha=1$ and $\\beta=1$, the beta distribution is equivalent to uniform distribution.\n",
    "\n",
    "### Bayes Theorem\n",
    "\n",
    "$$p(H \\mid D) = \\frac{p(H)p(D\\mid H)}{p(D)}$$\n",
    "$$p(H \\mid D) = posterior$$\n",
    "$$p(H) = \\text{prior, our belief before observing evidence}$$\n",
    "$$p(D \\mid H) = \\text{likelihood of seeing evidence D if hypothesis H is correct}$$\n",
    "$$p(D) = \\text{likelihood of evidence under any circumstance, normalizing factor}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "\n",
    "In the beginning, we don't have prior beliefs because we have not observed anything. So we start with $\\alpha=1$ and $\\beta=1$, i.e. all items have uniform, or equal probability.\n",
    "\n",
    "1. Sample random variable from each of 3 asset's beta distributions.\n",
    "2. Select the maximum random variable and show it to our user.\n",
    "3. Determine feedback on item, e.g. user click.\n",
    "4. Update the prior for selected item using feedback from (3).\n",
    "5. Repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Over Time\n",
    "\n",
    "Posteriors converge on expected value as we receive feedback from users.\n",
    "\n",
    "![alt text](./images/bayesian-methods.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking with Bayesian Methods\n",
    "\n",
    "- ranking scores is non-deterministic, we must sample from the posterior beta distributions\n",
    "- by sampling, ranking is intelligently random\n",
    "- this encourages *exploration*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Bandits Example Code\n",
    "\n",
    "[See bayesian-bandits notebook](./bayesian-bandits-code.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic-Based Learners\n",
    "- we can try to predict various targets using simple learning algorithms\n",
    "    - did user buy product?\n",
    "    - click on ad?\n",
    "    - click on article?\n",
    "    - sign up for newsletter?\n",
    "    - make an accountt?\n",
    "    - what rating did they give an item?\n",
    "- common demographic features include\n",
    "    - age, gender, religion, location, race, occupation\n",
    "    - education level, marital status, socio-economic status\n",
    "- other data from site\n",
    "    - date/location of sign up\n",
    "    - device type, mobile?\n",
    "    - page views\n",
    "    - credit card history\n",
    "    - purchase history\n",
    "- can purchase data\n",
    "    - Acxiom\n",
    "    - Intelius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Incorporate Product Data\n",
    "\n",
    "- above list includes only user features, how do we include product features?\n",
    "- can create a separate model for each item, but will not scale to many products\n",
    "- can add some product feature flags to the user feature vector and feed to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Variable Models\n",
    "\n",
    "- instead of explicit user features like age, gender, etc., we can learn implicit features\n",
    "- these learnes features are not as interpretable, but they are mathematically optimal and yield better results\n",
    "- this means we don't have to feature engineer features, saves time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page Rank\n",
    "\n",
    "The Page Rank of a page is the probability that a user would end up on a page if they surfed the Internet randomly for an infinite amount of time.\n",
    "\n",
    "Page Rank is just a score, and it can be applied to various recommender systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Models\n",
    "\n",
    "- Markov Model finds $x_t$ given $x_{t-1}$\n",
    "- [Visual explanations of MMs](https://setosa.io/ev/markov-chains/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- similar to bigrams in NLP - building a probabilistic language model that allows prediction of next word given current word\n",
    "    - what is probability of \"cats\" given \"love\" P(cats | love)\n",
    "- bigrams only consider 2 words at a time, which is limited, and more advanced language models use DNN models with recurrent and attention layers\n",
    "- instead of thinking about each item as a word, we think of it as a state $x(t)$\n",
    "- $x(t)$ only depends on $x_{t-1}$\n",
    "\n",
    "$$p(x_t \\mid x_{t-1}, x_{t-2}, \\dots, x_1) = p(x_t \\mid x_{t-1})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the **Transition* Probability Matrix A** defines the probability of transitioning from state *j* to state *i*\n",
    "- valid probabilities - rows of the matrix must sum up to 1\n",
    "- AKA as stochastic matrix or Markov matrix\n",
    "\n",
    "$$A(i,j) = p(x_t = j \\mid x_{t-1} = i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- how to calculate probabilities in transition matrix?\n",
    "\n",
    "$$p(rainy \\mid sunny) = \\frac{count(sunny \\rightarrow rainy)}{count(sunny)}$$\n",
    "\n",
    "- can use this method to calculate the probability of observing a sentence \"the quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "$$p(the)p(quick \\mid the)p(brown \\mid quick) \\dots$$\n",
    "$$p(x_1, \\dots, x_T) = p(x_1) \\prod_{t=2}^{T}{p(x_t \\mid x_{t-1})}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what if the test set contains a bigram that never occurs in the training data?\n",
    "- this *zero* probability will produce a 0 probability due to multiplication\n",
    "- therefore, we use add-1 smoothinng to prevent 0s in below equation, where V is equal to the total number of states\n",
    "\n",
    "$$p(x_t \\mid x_{t-1}) = \\frac{count(i \\rightarrow j) + 1}{count(i) + V}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **state distribution** $\\pi$ is the probability of being in a state at a given time\n",
    "- Example: if there are 2 possible states, sunny and rainy, $\\pi(t)$ will be a vector of size 2 $[p(x_t = sunny),p(x_t = rainy)]$\n",
    "- we can calculate $\\pi(t+1)$ using bayes rule, i.e. we can calculate the next state distribution\n",
    "\n",
    "$$\\pi_{t+1}(j) = \\sum_{i=1}^M{A(i,j)\\pi_t(i)}$$\n",
    "$$\\pi_{t+1} = \\pi_tA$$\n",
    "\n",
    "- we can predict the state *k* steps into the future\n",
    "\n",
    "$$\\pi_{t+k} = \\pi_tA^k$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- each web page on internet is modelled as a state in a Markov Model\n",
    "- we model transition probability using links on a page\n",
    "\n",
    "$$p(x_t = j \\mid x_{t-1} = i) = \\frac{1}{n(i)} \\text{if i links to j, otw 0}$$\n",
    "\n",
    "$$n(i) = # links on page i$$\n",
    "\n",
    "- there are billions of web pages, so very sparse and mostly 0, so smoothing must be applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Rankings\n",
    "\n",
    "- goal is to return list of items sorted by predicted ranking\n",
    "- how can we determine if our predicted ranking is good?\n",
    "- a number of metrics exist, recall, precision, etc, but these are not always the best method because sometimes we need models to explore new items, e.g. novel/surprising items. Users don't always want more of the same\n",
    "- no particular ranking can be \"correct\", we have to instead optimize metrics like revenue, impressions, clicks using A/B tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
